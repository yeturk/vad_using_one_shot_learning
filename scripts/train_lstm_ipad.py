import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import os
from tqdm import tqdm

print("\n ************    0. train_lstm_ipad.py is executed by yet :)    ************")

# ======================================================
# 1Ô∏è‚É£ Device Checking
# ======================================================
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚úÖ Device: {device}")

# ======================================================
# 2Ô∏è‚É£ Load Training Features
# ======================================================
train_path = "/home/yunus/projects/vad_using_one_shot_learning/dataset/IPAD_dataset/R01/training/features/01.npy"
train_features = np.load(train_path)
print(f"üìÇ Loaded training features: {train_features.shape}")

# ======================================================
# 3Ô∏è‚É£ Sequence Preparation
# ======================================================
sequence_length = 10  # 10 consecutive frame in every sequence
X = []
for i in range(len(train_features) - sequence_length):
    seq = train_features[i:i+sequence_length]
    X.append(seq)

X = np.array(X)
print(f"‚úÖ Prepared sequences: {X.shape}")

# Tensor formatƒ±na d√∂n√º≈üt√ºr
X_tensor = torch.tensor(X, dtype=torch.float32)
dataset  = TensorDataset(X_tensor, X_tensor)  # Autoencoder: input = output
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

# ======================================================
# 4Ô∏è‚É£ Define LSTM Autoencoder
# ======================================================
class LSTMAutoencoder(nn.Module):
    def __init__(self, input_dim=1280, hidden_dim=512, seq_len=10):
        super(LSTMAutoencoder, self).__init__()
        self.seq_len = seq_len
        self.hidden_dim = hidden_dim

        # Encoder
        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)

        # Decoder
        self.decoder = nn.LSTM(hidden_dim, input_dim, batch_first=True)

    def forward(self, x):
        _, (hidden, _) = self.encoder(x)
        # hidden ‚Üí decoder'a giri≈ü olarak ver
        hidden = hidden.repeat(self.seq_len, 1, 1).permute(1, 0, 2)
        reconstructed, _ = self.decoder(hidden)
        return reconstructed
    

# Model olu≈ütur
model = LSTMAutoencoder(input_dim=1280, hidden_dim=512, seq_len=sequence_length).to(device)
print(model)

# ======================================================
# 5Ô∏è‚É£ Training Setup
# ======================================================
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
epochs = 30

# ======================================================
# 6Ô∏è‚É£ Training Loop
# ======================================================
print("\nüöÄ Starting training...\n")
model.train()

for epoch in range(epochs):
    epoch_loss = 0.0
    for batch_X, _ in tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}"):
        batch_X = batch_X.to(device)
        optimizer.zero_grad()

        outputs = model(batch_X)
        loss = criterion(outputs, batch_X)

        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

    avg_loss = epoch_loss / len(dataloader)
    print(f"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.6f}")

print("\n‚úÖ Training completed!")

# ======================================================
# 7Ô∏è‚É£ Save Model
# ======================================================
os.makedirs("models", exist_ok=True)
torch.save(model.state_dict(), "models/lstm_ipad.pth")
print("üíæ Model saved to models/lstm_ipad.pth")